\documentclass[bachelor]{seuthesis} % 本科
% \documentclass[master]{seuthesis} % 硕士
% \documentclass[doctor]{seuthesis} % 博士
% \documentclass[engineering]{seuthesis} % 工程硕士
\usepackage{CJK,CJKnumb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\floatname{algorithm}{算法}
\renewcommand{\algorithmicrequire}{\textbf{输入:}}
\renewcommand{\algorithmicensure}{\textbf{输出:}}

 % 这里是导言区

\begin{document}
\categorynumber{000} % 分类采用《中国图书资料分类法》
\UDC{000}            %《国际十进分类法UDC》的类号
\secretlevel{公开}    %学位论文密级分为"公开"、"内部"、"秘密"和"机密"四种
\studentid{09013000}   %学号要完整，前面的零不能省略。

\title{无线通信网络中基于学习的分布式缓存方案研究}{}{Thesis Title}{subtitle}
\author{王驭扬}{Yuyang Wang}
\advisor{导师姓名}{教授}{Advisor's Name}{Prof.}
\coadvisor{副导师}{副教授}{Co-advisor's Name}{Associate Prof.} % 没有

% \degree{工学硕士} % 详细学位名称
\major[12em]{信息工程}
\defenddate{答辩日期}
\authorizedate{学位授予日期}
\department{信息科学与工程}{department name}
\duration{2016.12—2017.6}
\address{无线谷A5楼2层}
\thanks{本论文获国家XXX计划项目（2012AA00A00）和国家杰出青年科学基金项目（01234567）资助。}
\maketitle

\begin{abstract}{主动缓存，迁移学习，协同过滤，势博弈}
摘要写在这
\end{abstract}

\begin{englishabstract}{Proactive caching,Transfer learning,collaborative filtering,potential game}
英文摘要
\end{englishabstract}

\tableofcontents

\begin{terminology}
\begin{table}[h]
%\Large
\begin{tabular}{|>{\LARGE}m{0.2\textwidth}<{\centering}|m{0.8\textwidth}|}
\hline
\normalsize \hspace*{\stretch{1}}符号\hspace*{\stretch{1}} &
        \hspace*{\stretch{1}}含义\hspace*{\stretch{1}} \\
\hline
a & 如同汉字起源于象形，拉丁字母表中的每个字母一开始都是描摹某种动物或物体形状的图画\\
\hline
b&和A一样，字母B也可以追溯到古代腓尼基。在腓尼基字母表中B叫beth,代表房屋，在希伯来语中B也叫beth，也含房屋之意。\\
\hline
c& 字母C在腓尼基人的文字中叫gimel，代表骆驼。它在字母表中的排列顺序和希腊字母Γ(gamma)相同，实际上其字形是从后者演变而来的。C在罗马数字中表示100。\\
\hline
d&D在古时是描摹拱门或门的形状而成的象形符号，在古代腓尼基语和希伯来语中叫做daleth，是“门”的意思，相当于希腊字母Δ（delta）。\\
\hline
\end{tabular}
%\caption{my table}
\end{table}

\end{terminology}

\begin{Main} % 开始正文

\chapter{绪论}
\section{研究背景}
随着移动通信、移动智能终端以及社交网络的发展，人们开始越来越多的通过移动终端来体验丰富多样的在线服务，他们在工作、学习、生活等方面也正逐渐向移动互联网迁徙。在这个互联网快速发展的时代，人们开始注重移动网络带来的服务体验，也对快速获取更充实更有质量的内容提出了要求。用户需求层次的提高带动了大量新兴无线通信业务的发展，同时也带来了移动互联网的数据量爆炸式增长。最近的调查表明移动视频数据占据了移动数据量的一半左右，而且这项数据还在急速增长中。
为应对这种移动数据量的爆炸式增长，我们传统的方法是提高频谱资源（带宽），频谱效率（调制、编码、MIMO），或者空间复用（基站密度）。但是在实际应用条件下，这些方法提供的吞吐量增益相当有限，而且实现成本较高。除此之外，未来无线通信网络会更注重用户的体验，为此就需要更小的端到端的时延，但是现有无线通信网络对于每个用户的每个请求都会经过基站进行一次数据传输，长距离的高清视频传输必将导致服务延时较大，同时在终端数量爆炸式增长的情况下，这也会急剧增大基站的网络拥塞进而导致更大的服务时延。所以亟待寻找一种合适的方法来缓解这种窘境。无线通信网络缓存应运而生。
无线通信网络缓存可以利用网络边缘的各种端设备，如基站、移动终端。无线通信网络缓存之所以引起学术界及工业界的广泛关注，一方面是因为近年来缓存设备的价格不断下降，而且移动终端的存储空间越来越大；另一方面，无线网络缓存可通过提前缓存内容并利用无线网络边缘内部、边缘设备互相之间良好的短距离协作通信来传输内容，有效降低服务延时，也能减小基站的峰值速率、卸载基站的流量。
从研究方向来看，无线通信网络缓存主要研究缓存设计，利用5G网络的预测能力，结合关于机器学习和博弈论等方向的研究，设计出合理的缓存方案。可以预见，作为5G通信研究的一个重要方面，无线通信网络缓存将在提升用户体验、卸载基站流量，降低回程链路负载等方面做出贡献。
\section{研究现状}

\section{本文的主要内容}


\chapter{主动缓存概述}
\section{主动网络的提出背景}
近年来智能手机等移动设备的普及大大丰富了移动用户的体验，也带来了大量新的无线服务，包括多媒体，网络浏览和社交互联网络。这种现象进一步推动了移动视频流的发展，它目前占移动数据流量的近50％，并且预计在未来10年会增加500倍[1]。与此同时，第二大流量贡献者就是社交网络，其平均份额为15％[2]。这些现实情况都促使移动运营商去重新设计他们当前的网络，以寻求更先进和尖端的技术来增加网络的覆盖范围、提高网络容量，并且使内容更有效地贴近用户。\\
为满足这些前所未有的业务需求，部署小蜂窝网络（SCN）是一种可行的方法 [3]。小蜂窝网络是一种新型网络模型，其想法就是将短距离、低功率和低成本的小型基站（SBS）部署在宏蜂窝网络下。到目前为止，有很多关于自组织，小区间干扰协调（ICIC）的传输卸载，能量效率等方面的研究[3,及其中的引用文献]。这些研究是在现有的反应网络模型下进行的，他要求用户的业务请求和数据流必须在其到达或被丢弃时立即得到服务，而这会导致中断的出现。因此，现有的SCN模型不能满足峰值流量需求，其大规模部署也会带来高昂的站点获取、安装和回程成本。随着连接设备数量的激增以及超密集网络的出现，这些缺点将变得越来越严重，且会对当前的蜂窝网络基础设施造成损耗。解决这些问题的关键是构建一种超越当前异构小蜂窝网络的新网络模型，这种网络模型可以利用存储，情境感知和社交网络等领域的发展进行主动缓存。
\section{主动网络概述}
主动网络的 “主动性”植根于所有网络节点（即基站以及手持设备和智能电话），利用用户的情境感知，预测用户的需求并利用其预测能力来实现资源节省，同时保证服务质量要求（Qos）和成本/能源支出[5]。这种模型优越于目前的蜂窝网络部署方式，因为在蜂窝网络设计时，是假设设备是“傻瓜”的：存储和处理能力非常有限。然而，当前的智能手机已经变成一种非常复杂的设备，它具有更强的计算和存储能力。因此，在主动网络模型下，利用设备的功能和大量的可用数据，可以跟踪、学习网络中的用户并构建他们的需求简档以预测其未来可能的请求。使用机器学习技术来提取和分析大量的基础设施日志，以产生用于预测和内容推荐的、具有预测性和可操作性的信息[6]。具备了这些预测能力，通过在非高峰时间（例如夜间）主动提供对高峰时段需求的预测，可以用更有效的方式来调度用户，并且能更智能地预分配资源。这种主动网络模型通过巧妙地利用用户的上下文信息（即，文件受欢迎度的分布，用户位置，速度和移动性模式），能够更好地预测何时请求用户的内容、所需的资源量以及哪些网络位置的内容应该被预先缓存。
\section{主动网络框架下的主动缓存}
主动网络框架是在网络节点预测用户的需求，并利用它们的预测能力来降低网络流量的峰值均值比，这会使网络资源得到显著的节省。这种主动缓存方式利用了现有的异构蜂窝网络，涉及了预测无线电资源管理技术的设计，最大化了未来第五代（5G）网络的效率。\\
具体来讲，主动缓存基于一种概念，即移动用户的信息需求在某种程度上是可预测的。可以利用这种可预测性，通过在用户实际请求它之前，就已经主动地预先缓存所需的信息来最小化蜂窝网络的峰值负载。网络运营商可以利用智能手机的强大处理能力和大量存储空间，在非高峰时间主动提供关于峰值时断请求的预测。也就是说，当主动网络在截止时间前接收到用户的服务请求时，将相应的数据存储在用户设备中，并且当实际发起请求时，可以直接从缓存的存储器中拉出信息，不需要访问无线网络。为此，我们需要开发新的机器学习技术，以找到关于内容检索预测的最佳方式，解决用户从未发出请求和请求不能够及时服务的问题。显然，以本地方式在SBS和用户终端分析用户的业务和缓存内容可以减少回程流量，特别是当网络接收到大量内容类似的请求时回程节省会更加显著。因此，我们的目标是以智能方式预测和推断未来事件，我们认为这是由大量并且稀疏的信息/数据引起的复杂大数据问题[10]。事实上，数据的稀疏性是一个关键的挑战，因为我们可能不能从单个用户收集足够的数据，因而不能够准确地预测她/他的模式。为了克服这个挑战，可以利用其他用户的数据以及他们的社会关系来建立可靠的统计模型。而最重要的问题是，在一个时间窗内，哪些内容应该由SBS预先分配？什么时间（在哪个时隙应该被预先调度）去分配？是对哪些有战略性/有影响力的用户来预先分配？以及应在网络中的哪个位置进行？

\chapter{基于迁移学习和协同过滤的主动缓存技术}
\section{问题描述}
在本章中，我们具体讨论无线通信网络中的主动缓存技术。在我们的网络模型中，小基站（SBS）部署有大容量的存储单元，但回程链路的容量有限。文献[5]中提出了一种主动缓存过程，它是基于文件的受欢迎程度来存储文件，即缓存最受欢迎的文件，直到将缓存填满，而我们的研究也是基于这种方法。\\
首先我们假设网络中有$N$个用户和$F$个文件，文件的受欢迎程度矩阵为$P_{N\times F}$，矩阵中每行代表用户，而列代表文件，每个元素代表相应用户对相应文件的评分（评级）。在主动缓存过程中，我们需要有矩阵$P_{N\times F}$的完整信息。我们的主动缓存过程由训练和缓存安排两部分组成。在训练部分中，我们的目标就是估计受欢迎程度矩阵$P_{N\times F}$。\\
在实践中，文件的受欢迎程度矩阵较大、很稀疏、有大量的未知元素，因此我们就需要利用这个十分稀疏的矩阵的已知信息来预测矩阵中其他未知的元素。在解决这个问题时，我们受到Netflix推荐系统架构的启发，使用了监督机器学习和协同过滤（CF）的方法，提出了一个分布式主动缓存的过程，利用用户与文件的相关性来推断第$u$个用户请求第$i$个文件的概率。在利用CF技术进行机器学习的具体方法上，我们是通过正则化的奇异值分解（SVD）技术来完成的，即基于SVD的协同过滤。\\
然而，由于初始的受欢迎程度矩阵通常很大，稀疏，用户评级很少，就导致了CF学习方法的效率比较低下，这就是所谓的数据稀疏（data sparseness）和冷启动（cold-start）问题[13]。鉴于数据稀疏和冷启动问题降低了主动缓存的性能，我们考虑到了结合迁移学习（TL）框架及相关技术来进行机器学习和协同过滤[14]。使用TL是因为在许多现实世界的应用中，很难甚至不可能收集和标注足够的训练数据来构建合适的预测模型，但我们如果有其他相关的信息来源的大量数据信息，就可以利用这些丰富的数据来帮助我们来进行学习。具体的，在我们主动缓存问题中，设备与设备间（D2D）相互通信、交互的信息，即社交网络中的用户信息，就可以用来帮助我们实现迁移学习。我们将这种D2D交互的信息域称为源域，而我们所要解决的主动缓存问题所在信息域称为目标域。将源域中这些现有信息并入目标域中，可以用来优化我们的主动缓存技术。\\
接下来，我们将构建目标域与源域的网络模型，并具体介绍我们的基于SVD协同过滤方案，以及结合迁移学习来进行优化后的解决方案。
\section{网络模型}
\subsection{目标域}
我们考虑一种网络部署方案，它由$M_{tar}$个SBSs和$N_{tar}$个用户终端（UT）构成。每个SBS$m$都通过一个的回程链路连接到核心网络（CN）上，回程链路容量记为$C_m$，每个SBS 通过无线连接来为UTs提供服务，总无线链路容量记为$C'_m$。UTs请求的内容来源于一个由$F_{tar}$个文件构成的文件库中，其中每个内容$f$的大小为$L(f)$，比特率要求为$B(f)$。 此外，我们认为用户对内容的请求服从Zipf分布[15]：
\begin{equation}
P_f=\frac{1/f^\alpha}{\sum_{i=1}^{F_{tar}}1/i^\alpha}
\end{equation}
其中$\alpha$是描述分布特性的指数因子，反映了不同的文件受欢迎度分布情况。有了上述的文件受欢迎度分布情况，那么第$m$个SBS在时间$t$时的文件受欢迎度矩阵可以用$\textbf{P}^m(t)\in R^{N_{tar}\times F_{tar}}$来表示，其中每个元素$P_{n,f}^m(t)$表示第$n$个用户请求第$f$个文件内容的概率。\\
为了模拟用户请求内容时进行内容传送的情况，我们假设每一个SBS有固定的存储容量，大小为$S_m$，并从$F_{tar}$个文件中选择内容进行缓存。SBS能够依靠他们的本地缓存来对用户请求进行服务，对于减少峰值的请求量以及最小化内容传送的延迟是相当重要的。我们通过在合适的时间提前将CN中的内容，根据SBSs的存储容量情况来缓存在其中，来达到满足用户对内容的请求的同时，减少回程负载。为了实现这种想法，假设在时隙$T$内，用户发出的请求数量为$D$，请求集合记为$\textsl{D}=\{1,\dots,D\}$。如果一个请求$d\in\textsl{D}$在时间窗$T$内能被立即服务，那么我们认为该请求被满足，即内容传送的速度大于等于内容的比特率。因此用户的平均满意率可以由下式表示：
\begin{equation}
\eta(\textsl{D})=\frac{1}{D}\sum_{d\in\textsl{D}}L\{\frac{L(f_d)}{\tau'(d)-\tau(d)}\geq B(f_d)\}
\end{equation}
其中，$f_d$是所请求的内容，$L(f_d)$和$B(f_d)$分别是该内容的大小和比特率，$\tau(d)$和$\tau'(d)$分别是请求的到达时间和传送结束时间。$L\{\dots\}$是布尔函数，如果其中的表达式满足返回1，否则是0。假设在$t$时刻请求$d$的内容传送的瞬时回程速率为$R_d(t),R_d(t)\leq C_m$。那么平均回程负载可表示为：
\begin{equation}
\rho(\textsl{D})=\frac{1}{D}\sum_{d\in\textsl{D}}\frac{1}{L(f_d)}\sum_{t=\tau(f_d)}^{\tau'(f_d)}R_d(t)
\end{equation}
现在，记$\textbf{X}(t)\in\{0,1\}^{M_{tar}\times F_{tar}}$为SBSs的缓存决策矩阵，其中$x_{m,f}(t)$等于1表示在时间$t$第$f$个内容被第$m$个SBS缓存，等于0表示未缓存。为了简化问题，我们将SBSs的下标去掉，并假设在时隙$T$内内容的受欢迎度是一致的，因此$\textbf{P}^m(t)$可记为$\textbf{P}_{tar}$。我们将缓存策略限制为在非高峰时段内缓存文件，因此在内容传送时$\textbf{X}(t)$是固定的，记为$\textbf{X}$。这样我们目标域的主动缓存问题就归结为预测内容受欢迎度矩阵$\textbf{P}_{tar}$，从而得到缓存策略矩阵$\textbf{X}$。\\
接下来，由于源域的信息可以用来帮助我们解决目标域中$\textbf{P}_{tar}$的稀疏性问题，下面我们将考虑源域的情况。
\subsection{源域}
受到[2]的启发，我们可以利用一个基于D2D的社交网络，该社交网络由社交社区内的用户互动形成，我们将此信息域称为源域。这个源域包含用户在所在的社区内的交互行为，这种社交行为可以用中国餐馆过程（CRP）[16]来进行模拟。它们构成了迁移学习所需要用到的先验信息。\\
我们首先将源域中的用户数量定义为$N_{D2D}$，将内容总数定义为$F_{D2D}$。我们假设$F_{D2D}=F_0+F_h$，其中$F_h$表示有历史记录的内容集合，$F_0$表示没有历史记录的内容集合。在社交网络中，用户利用他们的社会关系寻求他们各自所需的内容。我们假设每个用户在所提供的内容中仅对一种类型的内容$f$感兴趣。我们假定内容（文件）$f$被给定用户$n$选择的概率遵循Beta分布（即先验分布）。因此，用户$n$的选择结果被定义为Beta分布（先验分布）的共轭概率，其遵循伯努利分布。考虑到这一点，用户选择文件的过程可模拟为CRP。CRP是基于一种比喻的说法，其中对象是餐馆中的客人，而类是他们所坐的桌子。特别地，在有着大量桌子的餐馆中，每个桌子具有无数个座位，顾客一个接一个地进入餐馆，并且每个人都随机选择桌子。在具有参数$\beta$的CRP中，每个客人以一个与占用者数量成比例的概率选择一张已被占用的桌子，而以与$\beta$成比例的概率选择下一空桌。具体的，第一个客人以$\beta/\beta=1$的概率选择第一张桌。第二个客人以$1/(1+\beta)$的概率选择第一张桌，以$\beta/(1+\beta)$的概率选择第二张桌。在第二个客人选择第二张桌之后，第三个客人以$1/(2+\beta)$的概率选择第一张桌，$1/(2+\beta)$的概率选择第二张桌，$\beta/(2+\beta)$的概率选择第三张桌。此过程一直持续到所有客人都有座位，该过程从而定义了客人与桌子间的分配。因此可以看出，后续客人的决策受到先前客人的反馈的影响，其中每个客人从先前客人的选择中学习以更新他们对桌子的看法和选择桌子的概率。\\
鉴于此，社交网络中的内容传播类似于CRP中的桌子选择。事实上，如果我们将所研究的网络视为中国餐馆，内容文件视为非常大量的桌子，而用户视为客人，那么我们可以通过CRP来理解内容的传播过程。也就是说，在每个社交圈内，用户按顺序请求下载他们所需的内容，并且当用户下载其内容时，进行记录（即下载历史）。反过来，该行为影响了社交社区内的其他用户请求这个相同内容的概率，其中受欢迎的内容会被更频繁地请求而新内容被请求的较少。记$\textbf{Z}_{D2D}\in\{0,1\}^{N_{D2D}\times F_{D2D}}$为指示每个用户选择哪些内容的随机二进制矩阵，其中如果用户$n$选择内容$f$，则$z_{n,f}=1$，否则为0。该矩阵概率可以表示如下[14]：
\begin{equation}
P(\textbf{Z}_{D2D})=\frac{\beta^{F_h}\Gamma(\beta)}{\Gamma(\beta+N_{D2D})}\prod_{f=1}^{F_h}(m_f-1)!
\end{equation}
其中$\Gamma(\dots)$是伽马函数，$m_f$是选择了内容$f$的用户数（即访问历史），$F_h$是有访问历史（即$m_f>0$）的内容的数量。\\
在目标域中，缓存问题归结为估计内容受欢迎度矩阵，而我们认为该矩阵十分的稀疏、大量元素是未知的，这导致了主动缓存性能较低。而在用户数量和内容文件数量越来越大的的现实情况下，这种问题可能会更加严重。因此，为了更有效地处理这些问题并缓存内容文件，我们提出了一种新的结合迁移学习的主动缓存技术，其中利用了从用户的社交网络交互中提取的丰富的信息（即源域信息）。
\section{基于SVD的CF算法}
协同过滤方法由训练和预测两个步骤构成。在训练阶段，我们的目标就是估计内容受欢迎度矩阵$\textbf{P}_{tar}\in R^{N_{tar}\times F_{tar}}$。其中每个SBS基于已知的信息（即用户对内容的评价）构建模型。在目标域中，稀疏的内容受欢迎度矩阵$\textbf{P}_{tar}$中的元素为$P_{tar,ij}$。在利用协同过滤估计内容受欢迎度矩阵时，我们将矩阵变换为如下的等价形式：$R_{tar}=\{(i,j,r):r=P_{tar,ij},P_{tar,ij}\neq0\}$，每行三个元素分别代表用户id、内容文件id和用户对文件的评分，该矩阵记录了所有已知的用户评价信息。为了预测$\textbf{P}_{tar}$中的未知元素，我们利用SVD对矩阵进行分解，构造一个秩为$k$的受欢迎度矩阵的一个估计$\textbf{P}_{tar}\approx \textbf{N}_{tar}^T\textbf{F}_{tar}$，其中因子矩阵分别为$\textbf{N}_{tar}\in R^{k\times N_{tar}}$和$\textbf{F}_{tar}\in R^{k\times F_{tar}}$，这两个因子矩阵的物理意义可以理解为，每个用户和文件分别有$k$个特征，矩阵的每行就是对应用户或文件的特征向量。那么显然该优化问题的目标函数可以写为预测值和真实值的误差平方和的形式：
\begin{equation}
\min_{i,j\in\textbf{P}_{tar}}\sum_{(i,j)\in\textbf{P}_{tar}}(P_{tar,ij}-n_i^Tf_j)^2
\end{equation}
其中训练集中的用户-文件对记为$(i,j)$，$n_i$和$f_j$分别表示$\textbf{N}_{tar}$和$\textbf{F}_{tar}$的第$i$和第$j$列。然而，若按照该公式针对已知评分数据进行训练，会过分地拟合这部分数据，这会导致模型的训练效果很差，这就是过拟合问题。为了避免过拟合的问题，我们在目标函数中加入正则化参数，该参数用来在正则化和拟合训练数据这两者之间进行平衡，因为对于目标函数来说，$n_i$矩阵和$f_j$矩阵中所有的值都是变量，而我们在不知道哪个变量会造成过拟合问题的情况下，对其中所有变量进行“惩罚”，这就是正则化的SVD，即RSVD，此时目标函数变为如下形式：
\begin{equation}
\min_{i,j\in\textbf{P}_{tar}}\sum_{(i,j)\in\textbf{P}_{tar}}(P_{tar,ij}-n_i^Tf_j)^2+\lambda(|n_i|^2+|f_j|^2)
\end{equation}
下面，我们对上述式子进行优化。为了更好地描述用户-文件对，我们将用户-文件对记为$(u.i)$，我们算法原始受欢迎度矩阵（即输入的训练矩阵）是$R_{tar}$，因此$P_{tar,ui}$对应于$R_{tar}$ 中的$r_{ui}$ 就是已知的评分真实值，将对应的特征向量$n_i$和$f_j$分别记为$p_u$ 和$q_i$，那么预测值就是$\hat{r}_{ui}=p_u^Tq_i$，为了方便，我们记真实值与预测值的误差为$e_{ui}=r_{ui}-\hat{r}_{ui}$。由于用户对文件的评分不仅取决于用户和文件之间的某种关系，还取决于用户和文件各自特有的性质，因此我们对预测值的公式加入基准线预测器，即$\hat{r}_{ui}=\mu+b_u+b_i+p_u^Tq_i$，其中$\mu$为总平均评分，$b_u$ 为用户$u$ 的属性相对于平均值$\mu$的偏移，$b_i$为文件$i$的属性相对于平均值$\mu$ 的偏移，$b_u$ 和$b_i$同样需要有正则化参数进行平衡，综上目标函数变为如下形式：
\begin{equation}
\min_{u,i\in\textbf{P}_{tar}}\sum_{(u,i)\in\textbf{P}_{tar}}(r_{ui}-\mu-b_u-b_i-p_u^Tq_i)^2+\lambda(b_u^2+b_i^2+|p_u|^2+|q_i|^2)
\end{equation}
有了上述的目标函数，我们只需要通过训练对它进行优化，我们的优化算法为随机梯度下降法。具体的，目标函数分别对变量$b_u$、$b_i$、$p_u$和$q_i$求偏导，再将这四个变量向负梯度方向变化，由此可得到四个变量的更新式如下：
\begin{equation}
b_u=b_u+\gamma(e_{ui}-\lambda b_u)
\end{equation}
\begin{equation}
b_i=b_i+\gamma(e_{ui}-\lambda b_i)
\end{equation}
\begin{equation}
p_u=p_u+\gamma(e_{ui}q_i-\lambda p_u)
\end{equation}
\begin{equation}
q_i=q_i+\gamma(e_{ui}p_u-\lambda q_i)
\end{equation}
在通过上述的CF算法进行训练时，我们需要了解当前估计值与真实值之间的偏差，对于误差的度量我们用“均方根误差”来度量。我们假设测试值矩阵为$R_{test}$，该矩阵与$R_{tar}$ 类似，每行3个数分别代表用户id、内容文件id和相应评分，显然测试值个数为$R_{test}$的行数$T_E$，现在我们将评估指标给出：
\begin{equation}
RMSE=\sqrt{\sum_{(u,i,r_{ui})\in R_{tar}}(r_{ui}-\hat{r}_{ui})^2/T_E}
\end{equation}
下面我们简要的给出基于SVD的CF算法的主要伪代码，具体代码会在附录或附件中给出。
\begin{algorithm}
    \caption{基于SVD的CF(1)}
    \begin{algorithmic}[1] %每行显示行号
        \Require $R_{tar}$原始训练矩阵，$R_{test}$测试矩阵
        \Ensure 估计矩阵$P$，评估指标$RMSE$
        \Function {LoadFileAndInitial}{$R_{tar},R_{test}$}
            \State Load $R_{tar},R_{test}$
            \State create arrays $bu[UserNum+1],bi[ItemNum+1],p[UserNum+1,dim]$
            \State create arrays $q[ItemNum+1,dim],RateMatrix[UserNum+1][ItemNum+1]$
            \State $RateMatrix,mean \gets R_{tar}$  
            \For{every element in $bu,bi,p,q$}
                \State $bu\gets0,bi\gets0,p\gets rand()/10,q\gets rand()/10$
            \EndFor      
        \EndFunction
        \Function {Train}{$gamma,lambda,nIter$}
        \State $Rmse\gets0,LastRmse\gets100000,RateNum\gets0,rui\gets0$
        \For{$n=1\to nIter$}
            \State $Rmse\gets0,RateNum\gets0$
            \For{$i=1\to UserNum$}
                \For{$j=1\to IterNum$}
                    \State $rui\gets mean+bu[i]+bi[j]+p[i]\cdot q[j],e\gets RateMatrix[i][j]-rui$
                    \State $bu[i]\gets bu[i]+gamma*(e-lambda*bu[i])$
                    \State $bi[j]\gets bi[j]+gamma*(e-lambda*bi[j])$
                    \For{$k=0\to dim-1$}
                        \State $p[i][k]\gets p[i][k]+gamma*(e*q[j][k]-lambda*p[i][k])$
                        \State $q[j][k]\gets q[j][k]+gamma*(e*p[i][k]-lambda*q[j][k])$
                    \EndFor 
                    \State $Rmse\gets Rmse+e^2,RateNum\gets RateNum+1$
                \EndFor
            \EndFor
            \State $Rmse\gets\sqrt{Rmse/RateNum}$
            \If{$Rmse>LastRmse$}
                \State $break$
            \EndIf
            \State $LastRmse\gets Rmse,gamma\gets gamma*0.9$
        \EndFor
        \For{$i=1\to UserNum$}
                \For{$j=1\to IterNum$}
                    \State $P[i][j]\gets mean+bu[i]+bi[j]+p[i]\cdot q[j]$
                \EndFor
        \EndFor  
        \State \Return{$P$}
        \EndFunction
    \end{algorithmic}
\end{algorithm}
\newpage
\begin{algorithm}
    \caption{基于SVD的CF(2)}
    \begin{algorithmic}[1] %每行显示行号
        \Function {Predict}{}
        \State $Rmse\gets0,Num\gets0$
        \For{every row $i$ of $R_{test}$}
            \State $userid\gets R_{test}[i][0],itemid\gets R_{test}[i][1],rate\gets R_{test}[i][2]$
            \State $rui\gets mean+bu[userId]+bi[itemId]+p[userId]\cdot q[itemId]$
            \State $Rmse\gets Rmse+(rate-rui)^2,Num\gets Num+1$
        \EndFor
        \State $Rmse\gets\sqrt{Rmse/Num}$
        \State \Return{$Rmse$}
        \EndFunction
        \Function {main}{}
        \State \Call{LoadFileAndInitial}{$R_{tar},R_{test}$}
        \State \Call{Train}{$gamma,lambda,nIter$},\Call{Predict}{}
        \EndFunction
    \end{algorithmic}
\end{algorithm}
\section{结合迁移学习的内容缓存算法}
为了应对目标域中数据稀疏的问题，我们利用来自与目标域不同但有一定相关性的源域的大量可用信息（即先验信息），进行迁移学习，可以更有效地解决主动缓存问题。我们记源域为$S^(S)$，并假设源域中有$N_{D2D}$个用户和$F_{D2D}$个内容文件，他们的集合分别为$\textbf{N}_{D2D}$和$\textbf{F}_{D2D}$，源域中的用户内容受欢迎度矩阵由矩阵$\textbf{P}_{D2D}\in R^{N_{D2D}\times F_{D2D}}$给出，相应的$R_{D2D}=\{(i,j,r):r=P_{D2D,ij},P_{D2D,ij}\neq0\}$表示源域中可知的用户对内容的评价。记目标域为$S^(T)$，我们这里采取迁移学习方法的基本思想就是是巧妙地“借用”$S^(S)$中用户的社会行为信息，来更好地学习$S^(T)$。\\
从源域到目标域的迁移学习过程分为两个阶段。首先，我们建立源域与目标域之间用户-内容文件的相关性。然后，为了实现知识迁移，结合源域与目标域来建立优化问题，通过学习不断优化目标域中受欢迎度矩阵$P_{tar}$的估计。具体来说，我们假设源域和目标域都与一个信息系统$s\in\{S^(S),S^(T)\}$相关，该信息系统中有$N_{s}$个用户和$F_{s}$个内容文件，他们的集合分别为$\textbf{N}_{s}$和$\textbf{F}_{s}$，令$R_{s}=\{(i,j,r):r=P_{s,ij},P_{s,ij}\neq0\}$表示$s$中可知的用户对内容的评价。令$\textbf{N}_{s}=\textbf{N}_{D2D}\cup\textbf{N}_{tar}$且$\textbf{F}_{s}=\textbf{F}_{D2D}\cup\textbf{F}_{tar}$，其中$N_s=|\textbf{N}_{s}|$和$F_s=|\textbf{F}_{s}|$分别表示该系统中的用户数和内容文件数。\\
在利用迁移学习时，我们同样需要建立用户因子矩阵$\textbf{F}
\in R^{N_{D2D}\times F_{D2D}}$

\end{Main} % 结束正文

\begin{Acknowledgement}
感谢……
\end{Acknowledgement}

% 参考文献
\bibliography{seuthesis}

\begin{Appendix}
  \chapter{第一个附录}
  ……
\end{Appendix}

\newpage
\printindex % 索引

%\begin{thebibliography}{99}


%\bibliographystyle{ieee}
%\bibliography{seuthesis}




\begin{Resume}
作者简介
\end{Resume}

\end{document}
